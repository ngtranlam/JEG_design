import requests
import base64
import io
from PIL import Image
import json
import hashlib
import os
import time
from typing import Optional, Tuple
from pathlib import Path

# Import Google GenAI library
try:
    from google import genai
    from google.genai import types
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Warning: google.genai library not available. Install with: pip install google-genai")

class GeminiClient:
    """
    Client for Google Gemini API to handle background removal and image processing
    """
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models"
        self.headers = {
            "x-goog-api-key": api_key,
            "Content-Type": "application/json"
        }
        # Setup cache directory - use user's home directory for PyInstaller compatibility
        import os
        import tempfile
        
        # Try to use user's home directory first, fallback to temp directory
        try:
            home_dir = Path.home()
            self.cache_dir = home_dir / "JEGDesignExtract" / "extract_cache"
        except:
            self.cache_dir = Path(tempfile.gettempdir()) / "JEGDesignExtract" / "extract_cache"
        
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    # def remove_background_with_gemini(self, image_data: bytes, model: str = "gemini-2.5-flash") -> Optional[Image.Image]:
    #     """
    #     Remove background from image using Gemini API
        
    #     Args:
    #         image_data: Image bytes
    #         model: Gemini model to use
            
    #     Returns:
    #         PIL Image with transparent background or None if failed
    #     """
    #     try:
    #         # Convert image to base64
    #         image_base64 = base64.b64encode(image_data).decode('utf-8')
            
    #         # Determine MIME type
    #         mime_type = "image/jpeg"
    #         if image_data.startswith(b'\x89PNG'):
    #             mime_type = "image/png"
    #         elif image_data.startswith(b'GIF'):
    #             mime_type = "image/gif"
            
    #         # Create the prompt for background removal
    #         # prompt = """
    #         # Please remove the background from this image and return only the main subject/design with a transparent background. 
            
    #         # Requirements:
    #         # - Keep all details, colors, and text exactly as they appear
    #         # - Remove any background, shadows, or unwanted elements
    #         # - Output should be a clean PNG with transparent background
    #         # - Maintain the original quality and sharpness
    #         # - If this is a design on clothing, extract only the design part
    #         # """
            
    #         prompt ="""
    #                 Nh∆∞ m·ªôt designer chuy√™n nghi·ªáp, h√£y v·∫Ω l·∫°i thi·∫øt k·∫ø n√†y tr√™n n·ªÅn chrome key v·ªõi c√°c y√™u c·∫ßu sau:
    #                 - Ch·ªçn m√†u chrome key c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n cao nh·∫•t v·ªõi c√°c m√†u c√≥ trong thi·∫øt k·∫ø (c√≥ 3 m√†u n·ªÅn ch√≠nh l√† Green screen, Blue screen, Red screen)
    #                 - C√°c chi ti·∫øt c·ªßa h√¨nh ·∫£nh ƒë∆∞·ª£c v·∫Ω l·∫°i ho√†n to√†n, gi·ªØ nguy√™n m√†u s·∫Øc, vƒÉn b·∫£n, h√¨nh ·∫£nh v√† chi ti·∫øt nh∆∞ trong h√¨nh g·ªëc.
    #                 - CƒÉn ch·ªânh ƒë·∫∑t thi·∫øt k·∫ø m·ªõi v√†o gi·ªØa khung ·∫£nh m·ªõi v√† cƒÉn th·∫≥ng.
    #                 """
    #         # Prepare the request payload
    #         payload = {
    #             "contents": [
    #                 {
    #                     "parts": [
    #                         {
    #                             "inline_data": {
    #                                 "mime_type": mime_type,
    #                                 "data": image_base64
    #                             }
    #                         },
    #                         {
    #                             "text": prompt
    #                         }
    #                     ]
    #                 }
    #             ],
    #             "generationConfig": {
    #                 "temperature": 0.1,
    #                 "topK": 1,
    #                 "topP": 0.8,
    #                 "maxOutputTokens": 1024
    #             }
    #         }
            
    #         # Make API request
    #         model_url = f"{self.base_url}/{model}:generateContent"
    #         response = requests.post(model_url, headers=self.headers, json=payload, timeout=60)
            
    #         if response.status_code == 200:
    #             result = response.json()
                
    #             # Extract the generated image from response
    #             if "candidates" in result and len(result["candidates"]) > 0:
    #                 candidate = result["candidates"][0]
    #                 if "content" in candidate and "parts" in candidate["content"]:
    #                     parts = candidate["content"]["parts"]
                        
    #                     # Look for image data in the response
    #                     for part in parts:
    #                         if "inline_data" in part:
    #                             # Decode the base64 image
    #                             image_data = base64.b64decode(part["inline_data"]["data"])
    #                             return Image.open(io.BytesIO(image_data))
    #                         elif "text" in part:
    #                             # If text response, try to extract image from text description
    #                             # This is a fallback - Gemini might not return image directly
    #                             print(f"Text response: {part['text']}")
    #                             continue
                
    #             print("No image data found in Gemini response")
    #             return None
    #         else:
    #             print(f"Gemini API error: {response.status_code} - {response.text}")
    #             return None
                
    #     except Exception as e:
    #         print(f"Error calling Gemini API: {str(e)}")
    #         return None
    
    def _get_cache_key(self, image_data: bytes, model: str, processing_type: str = "print", prompt: str = None) -> str:
        """Generate cache key for image data, model, processing type and prompt"""
        hasher = hashlib.md5()
        hasher.update(image_data)
        hasher.update(model.encode())
        hasher.update(processing_type.encode())
        if prompt:
            hasher.update(prompt.encode())
        return hasher.hexdigest()
    
    def _get_cached_result(self, cache_key: str) -> Optional[Image.Image]:
        """Get cached result if exists"""
        cache_file = self.cache_dir / f"gemini_extracted_{cache_key}.png"
        if cache_file.exists():
            try:
                return Image.open(cache_file)
            except Exception as e:
                print(f"Error loading cached result: {e}")
                cache_file.unlink(missing_ok=True)  # Remove corrupted cache
        return None
    
    def _save_to_cache(self, cache_key: str, image: Image.Image):
        """Save result to cache"""
        try:
            cache_file = self.cache_dir / f"gemini_extracted_{cache_key}.png"
            image.save(cache_file, "PNG")
            print(f"Saved result to cache: {cache_file}")
        except Exception as e:
            print(f"Error saving to cache: {e}")
    
    def clear_cache(self):
        """Clear all cached results"""
        try:
            for cache_file in self.cache_dir.glob("gemini_extracted_*.png"):
                cache_file.unlink()
            print("‚úÖ Cache cleared successfully")
        except Exception as e:
            print(f"Error clearing cache: {e}")
    
    
    def extract_design_with_gemini(self, image_data: bytes, model: str = "gemini-2.5-flash-image-preview", processing_type: str = "print", prompt: str = None) -> Optional[Image.Image]:
        """
        Extract design from image using Gemini Image Generation API with caching
        
        Args:
            image_data: Image bytes
            model: Gemini model to use (should be gemini-2.5-flash-image-preview)
            processing_type: "print", "embroidery", or "mockup" - determines the prompt style
            prompt: Custom prompt to use (overrides processing_type prompt)
            
        Returns:
            PIL Image with extracted design or None if failed
        """
        try:
            # Check cache first
            cache_key = self._get_cache_key(image_data, model, processing_type, prompt)
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                print("‚úÖ Using cached Gemini result")
                return cached_result
            # Convert image to base64
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # Determine MIME type
            mime_type = "image/jpeg"
            if image_data.startswith(b'\x89PNG'):
                mime_type = "image/png"
            elif image_data.startswith(b'GIF'):
                mime_type = "image/gif"
            
            # Choose prompt based on processing type or use custom prompt
            if prompt:
                # Use custom prompt (for mockup mode)
                print(f"üìù Using custom prompt:")
                print(f"   {prompt}")
                print("=" * 80)
            elif processing_type.lower() == "embroidery":
                # prompt = "V·∫Ω l·∫°i thi·∫øt k·∫ø n√†y theo phong c√°ch th√™u th·ª±c t·∫ø v·ªõi ch·ªâ len. Sau ƒë√≥ t·∫°o mockup tr√™n √°o thun g·∫•p g·ªçn ƒë·ªÉ b√°n tr√™n Etsy, c√≥ trang tr√≠ m·ªôt v√†i ƒëi·ªÉm trang tr√≠ ƒë·ªÉ l√†m cho n√≥ tr√¥ng th·ª±c t·∫ø."
                prompt = "Nh∆∞ m·ªôt Designer chuy√™n nghi·ªáp, h√£y th·ª±c hi·ªán v·∫Ω l·∫°i thi·∫øt k·∫ø n√†y theo phong c√°ch th√™u th·ª±c t·∫ø tr√™n n·ªÅn xanh l√° t∆∞∆°i c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n cao ph√π h·ª£p cho vi·ªác t√°ch n·ªÅn. Thi·∫øt k·∫ø ƒë∆∞·ª£c kh√¢u b·∫±ng ch·ªâ, c√°c ƒë∆∞·ªùng ch·ªâ th√™u ngang v√† cƒÉng b√≥ng, v·ªõi k·∫øt c·∫•u r√µ r√†ng v√† th·ªÉ hi·ªán t·ªët ƒë·ªô s√¢u 3D. Ch·ªâ th·ª±c hi·ªán th√™u ph·∫ßn thi·∫øt k·∫ø, ph·∫ßn n·ªÅn l√† m√†u xanh Chromakey ho√†n to√†n."
            else:
                # Default print prompt
                prompt = """
                        Nh∆∞ m·ªôt designer chuy√™n nghi·ªáp, h√£y v·∫Ω l·∫°i thi·∫øt k·∫ø n√†y tr√™n n·ªÅn xanh l√° t∆∞∆°i c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n cao ph√π h·ª£p cho vi·ªác t√°ch n·ªÅn. V·ªõi c√°c chi ti·∫øt c·ªßa h√¨nh ·∫£nh ƒë∆∞·ª£c v·∫Ω l·∫°i ho√†n to√†n, gi·ªØ nguy√™n m√†u s·∫Øc, vƒÉn b·∫£n, h√¨nh ·∫£nh v√† chi ti·∫øt nh∆∞ trong h√¨nh g·ªëc. H√£y lo·∫°i b·ªè watermark v√† logo n·∫øu c√≥ tr√™n h√¨nh. ƒêi·ªÅu ch·ªânh cƒÉn gi·ªØa v√† th·∫≥ng, ƒë·∫∑t thi·∫øt k·∫ø l·ªõn l√™n v·ª´a b·∫±ng khung ·∫£nh.
                        """
                print(f"üìù Using PRINT prompt:")
                print(f"   {prompt}")
                print("=" * 80)
            
            # Prepare the request payload for image generation
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            },
                            {
                                "inline_data": {
                                    "mime_type": mime_type,
                                    "data": image_base64
                                }
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.1,
                    "topK": 16,
                    "topP": 0.7,
                    "maxOutputTokens": 8192
                }
            }
            
            # Make API request to image generation model
            model_url = f"{self.base_url}/{model}:generateContent"
            response = requests.post(model_url, headers=self.headers, json=payload, timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                print(f"API Response structure: {list(result.keys())}")
                
                # Process response according to Gemini Image Generation API format
                if "candidates" in result and len(result["candidates"]) > 0:
                    candidate = result["candidates"][0]
                    print(f"Candidate structure: {list(candidate.keys())}")
                    
                    if "content" in candidate and "parts" in candidate["content"]:
                        parts = candidate["content"]["parts"]
                        print(f"Found {len(parts)} parts in response")
                        
                        # Look for image data in the response parts
                        for i, part in enumerate(parts):
                            print(f"Part {i}: {list(part.keys())}")
                            
                            # Check for inline_data (base64 image)
                            if "inline_data" in part or "inlineData" in part:
                                inline_data = part.get("inline_data") or part.get("inlineData")
                                if inline_data and "data" in inline_data:
                                    print("Found image data in response!")
                                    # Decode the base64 image
                                    image_data_b64 = inline_data["data"]
                                    image_bytes = base64.b64decode(image_data_b64)
                                    raw_image = Image.open(io.BytesIO(image_bytes))
                                    
                                    # Use image directly from API (no background removal)
                                    result_image = raw_image.convert('RGBA') if raw_image.mode != 'RGBA' else raw_image
                                    
                                    # Save processed result to cache
                                    self._save_to_cache(cache_key, result_image)
                                    
                                    return result_image
                            
                            # Log text responses for debugging
                            elif "text" in part:
                                print(f"Text response: {part['text'][:200]}...")
                
                print("No image data found in Gemini response - trying alternative prompt")
                
                # Try with alternative prompt
                if processing_type.lower() == "embroidery":
                    # alternative_prompt = "V·∫Ω l·∫°i thi·∫øt k·∫ø n√†y theo phong c√°ch th√™u th·ª±c t·∫ø v·ªõi ch·ªâ len. Sau ƒë√≥ t·∫°o mockup tr√™n √°o thun g·∫•p g·ªçn ƒë·ªÉ b√°n tr√™n Etsy, c√≥ trang tr√≠ m·ªôt v√†i ƒëi·ªÉm trang tr√≠ ƒë·ªÉ l√†m cho n√≥ tr√¥ng th·ª±c t·∫ø."
                    alternative_prompt =  "Nh∆∞ m·ªôt Designer chuy√™n nghi·ªáp, h√£y th·ª±c hi·ªán v·∫Ω l·∫°i thi·∫øt k·∫ø n√†y theo phong c√°ch th√™u th·ª±c t·∫ø tr√™n n·ªÅn xanh l√° t∆∞∆°i c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n cao ph√π h·ª£p cho vi·ªác t√°ch n·ªÅn. Thi·∫øt k·∫ø ƒë∆∞·ª£c kh√¢u b·∫±ng ch·ªâ, c√°c ƒë∆∞·ªùng ch·ªâ th√™u ngang v√† cƒÉng b√≥ng, v·ªõi k·∫øt c·∫•u r√µ r√†ng v√† th·ªÉ hi·ªán t·ªët ƒë·ªô s√¢u 3D. Ch·ªâ th·ª±c hi·ªán th√™u ph·∫ßn thi·∫øt k·∫ø, ph·∫ßn n·ªÅn l√† m√†u xanh Chromakey ho√†n to√†n."
                else:
                    alternative_prompt = """
                                        Nh∆∞ m·ªôt designer chuy√™n nghi·ªáp, h√£y v·∫Ω l·∫°i thi·∫øt k·∫ø n√†y tr√™n n·ªÅn xanh l√° t∆∞∆°i c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n cao ph√π h·ª£p cho vi·ªác t√°ch n·ªÅn. V·ªõi c√°c chi ti·∫øt c·ªßa h√¨nh ·∫£nh ƒë∆∞·ª£c v·∫Ω l·∫°i ho√†n to√†n, gi·ªØ nguy√™n m√†u s·∫Øc, vƒÉn b·∫£n, h√¨nh ·∫£nh v√† chi ti·∫øt nh∆∞ trong h√¨nh g·ªëc. H√£y lo·∫°i b·ªè watermark v√† logo n·∫øu c√≥ tr√™n h√¨nh. ƒêi·ªÅu ch·ªânh cƒÉn gi·ªØa v√† th·∫≥ng, ƒë·∫∑t thi·∫øt k·∫ø l·ªõn l√™n v·ª´a b·∫±ng khung ·∫£nh.
                                        """
                # Try alternative request
                alt_payload = {
                    "contents": [
                        {
                            "parts": [
                                {"text": alternative_prompt},
                                {
                                    "inline_data": {
                                        "mime_type": mime_type,
                                        "data": image_base64
                                    }
                                }
                            ]
                        }
                    ],
                    "generationConfig": {
                        "temperature": 0.05,
                        "topK": 8,
                        "topP": 0.6,
                        "maxOutputTokens": 4096
                    }
                }
                
                print("üîÑ Trying alternative prompt...")
                alt_response = requests.post(model_url, headers=self.headers, json=alt_payload, timeout=120)
                
                if alt_response.status_code == 200:
                    alt_result = alt_response.json()
                    if "candidates" in alt_result and len(alt_result["candidates"]) > 0:
                        candidate = alt_result["candidates"][0]
                        if "content" in candidate and "parts" in candidate["content"]:
                            parts = candidate["content"]["parts"]
                            for part in parts:
                                if "inline_data" in part or "inlineData" in part:
                                    inline_data = part.get("inline_data") or part.get("inlineData")
                                    if inline_data and "data" in inline_data:
                                        print("‚úÖ Found image data in alternative response!")
                                        image_data_b64 = inline_data["data"]
                                        image_bytes = base64.b64decode(image_data_b64)
                                        raw_image = Image.open(io.BytesIO(image_bytes))
                                        
                                        # Use image directly from API (no background removal)
                                        result_image = raw_image.convert('RGBA') if raw_image.mode != 'RGBA' else raw_image
                                        
                                        # Save processed result to cache
                                        self._save_to_cache(cache_key, result_image)
                                        
                                        return result_image
                
                print("‚ùå Both attempts failed to generate image")
                print(f"Original response: {result}")
                return None
            else:
                print(f"Gemini API error: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"Error calling Gemini API: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def test_connection(self) -> bool:
        """
        Test the connection to Gemini API
        
        Returns:
            True if connection successful, False otherwise
        """
        try:
            # Test with image generation model
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": "Hello, this is a connection test."
                            }
                        ]
                    }
                ]
            }
            
            # Test with the image generation model
            model_url = f"{self.base_url}/gemini-2.5-flash-image-preview:generateContent"
            response = requests.post(model_url, headers=self.headers, json=payload, timeout=10)
            
            if response.status_code == 200:
                print("‚úÖ Gemini API connection test successful")
                return True
            else:
                print(f"‚ùå Gemini API connection test failed: {response.status_code} - {response.text}")
                return False
            
        except Exception as e:
            print(f"Gemini API connection test failed: {str(e)}")
            return False

    def generate_dual_videos_from_image(self, image_path: str, combined_script: str) -> Optional[str]:
        """
        Generate 2 videos with different camera angles and merge them into one 16s video
        
        Args:
            image_path: Path to the input image
            combined_script: Combined script containing both video scripts
            
        Returns:
            Path to merged 16s video file or None if failed
        """
        try:
            if not self.api_key:
                print("‚ùå API key not provided")
                return None
            
            if not GENAI_AVAILABLE:
                print("‚ùå Google GenAI library not available. Please install with: pip install google-genai")
                return None
            
            print("üé¨ Starting dual video generation with Gemini Veo3...")
            
            # Extract individual scripts from combined script
            try:
                # Split the combined script to get individual scripts
                parts = combined_script.split("üé¨ VIDEO 2 (8s) - FULL BODY MOVEMENT:")
                if len(parts) >= 2:
                    script1_part = parts[0].replace("üé¨ VIDEO 1 (8s) - CLOSE-UP FOCUS:", "").strip()
                    script2_part = parts[1].split("üìù FINAL:")[0].strip()
                else:
                    # Fallback to original method if script format is different
                    script1_part = combined_script
                    script2_part = combined_script
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Could not parse combined script, using fallback: {e}")
                script1_part = combined_script
                script2_part = combined_script
            
            # Create 2 different prompts using the individual scripts
            prompt1 = f"{script1_part}\n\n**Technical Requirements:**\n- T·ªâ l·ªá khung h√¨nh: 9:16 (vertical) - FULL FRAME\n- Th·ªùi l∆∞·ª£ng: 8 gi√¢y\n- Focus: Close-up details c·ªßa thi·∫øt k·∫ø √°o\n- NO TEXT, NO SUBTITLES, NO OVERLAY - ch·ªâ video thu·∫ßn\n- Fill to√†n b·ªô khung h√¨nh 9:16, kh√¥ng c√≥ vi·ªÅn ƒëen"
            
            prompt2 = f"{script2_part}\n\n**Technical Requirements:**\n- T·ªâ l·ªá khung h√¨nh: 9:16 (vertical) - FULL FRAME\n- Th·ªùi l∆∞·ª£ng: 8 gi√¢y\n- Focus: Full body movement v√† dynamic shots\n- NO TEXT, NO SUBTITLES, NO OVERLAY - ch·ªâ video thu·∫ßn\n- Fill to√†n b·ªô khung h√¨nh 9:16, kh√¥ng c√≥ vi·ªÅn ƒëen"
            
            print(f"üìù Prompt 1 (Close-up): {prompt1[:100]}...")
            print(f"üìù Prompt 2 (Medium): {prompt2[:100]}...")
            
            # Generate both videos
            video1_path = self.generate_video_from_image(image_path, prompt1)
            if not video1_path or not os.path.exists(video1_path):
                print("‚ùå Failed to generate first video")
                return None
                
            print(f"‚úÖ First video generated successfully: {video1_path}")
            
            video2_path = self.generate_video_from_image(image_path, prompt2)
            if not video2_path or not os.path.exists(video2_path):
                print("‚ùå Failed to generate second video")
                
            print(f"‚úÖ Second video generated successfully: {video2_path}")
            
            # Merge videos using ffmpeg
            merged_video_path = self._merge_videos(video1_path, video2_path)
            
            if merged_video_path:
                print(f"‚úÖ Videos merged successfully: {merged_video_path}")
                return merged_video_path
            else:
                print("‚ö†Ô∏è Failed to merge videos, returning first video as fallback")
                print(f"üí° Install ffmpeg to enable 16s merged videos: brew install ffmpeg")
                return video1_path
                
        except Exception as e:
            print(f"‚ùå Error in dual video generation: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def generate_video_from_image(self, image_path: str, prompt: str) -> Optional[str]:
        """
        Generate video from image using Gemini Veo3 API with Google GenAI library
        
        Args:
            image_path: Path to the input image
            prompt: Text prompt for video generation
            
        Returns:
            Path to generated video file or None if failed
        """
        try:
            if not self.api_key:
                print("‚ùå API key not provided")
                return None
            
            if not GENAI_AVAILABLE:
                print("‚ùå Google GenAI library not available. Please install with: pip install google-genai")
                return None
            
            print("üé¨ Starting video generation with Gemini Veo3...")
            print(f"üìù Prompt: {prompt[:100]}...")
            
            # Initialize Google GenAI client
            client = genai.Client(api_key=self.api_key)
            
            # Read image file
            with open(image_path, 'rb') as f:
                image_data = f.read()
            
            # Convert image to base64
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # Determine MIME type
            mime_type = "image/jpeg"
            if image_data.startswith(b'\x89PNG'):
                mime_type = "image/png"
            elif image_data.startswith(b'GIF'):
                mime_type = "image/gif"
            
            print("üì§ Generating video with Veo3...")
            
            # Generate video using Veo3 with config
            operation = client.models.generate_videos(\
                model="veo-3.0-generate-001",
                prompt=prompt,
                image=types.Image(
                    image_bytes=image_data,
                    mime_type=mime_type
                ),
                config=types.GenerateVideosConfig(
                    aspect_ratio="9:16",
                    person_generation="allow_adult"
                )
            )
            
            print("‚è≥ Polling for completion...")
            
            # Poll the operation status until the video is ready
            while not operation.done:
                print("Waiting for video generation to complete...")
                time.sleep(10)
                operation = client.operations.get(operation)
            
            print("‚úÖ Video generation completed!")
            
            # Debug: Check operation structure
            print(f"Operation response: {operation.response}")
            print(f"Operation result: {operation.result}")
            
            # Get the generated video - try different possible structures
            video = None
            if operation.response and hasattr(operation.response, 'generated_videos'):
                video = operation.response.generated_videos[0]
            elif operation.result and hasattr(operation.result, 'generated_videos'):
                video = operation.result.generated_videos[0]
            elif hasattr(operation, 'generated_videos'):
                video = operation.generated_videos[0]
            else:
                print("‚ùå Could not find generated_videos in operation")
                print(f"Available attributes: {dir(operation)}")
                if operation.response:
                    print(f"Response attributes: {dir(operation.response)}")
                if operation.result:
                    print(f"Result attributes: {dir(operation.result)}")
                return None
            
            if not video:
                print("‚ùå No video found in operation")
                return None
            
            # Setup video cache directory
            video_cache_dir = self.cache_dir.parent / "video_cache"
            video_cache_dir.mkdir(parents=True, exist_ok=True)
            
            # Save video to cache
            video_filename = f"generated_video_{int(time.time())}.mp4"
            video_path = video_cache_dir / video_filename
            
            # Download and save the video
            client.files.download(file=video.video)
            video.video.save(str(video_path))
            
            print(f"‚úÖ Video saved to: {video_path}")
            return str(video_path)
                
        except Exception as e:
            print(f"‚ùå Error calling Veo3 API: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def generate_text(self, prompt: str) -> Optional[str]:
        """Generate text using Gemini API."""
        try:
            if not GENAI_AVAILABLE:
                print("‚ùå Google GenAI library not available. Please install with: pip install google-genai")
                return None
            
            print(f"üìù Generating text with gemini-2.5-pro...")
            print(f"üìù Prompt: {prompt[:100]}...")
            
            # Initialize client with API key
            client = genai.Client(api_key=self.api_key)
            
            # Generate text using gemini-2.5-pro
            response = client.models.generate_content(
                model="gemini-2.5-pro",
                contents=prompt
            )
            
            if response and response.text:
                print("‚úÖ Text generated successfully!")
                return response.text
            else:
                print("‚ùå No text generated")
                return None
                
        except Exception as e:
            print(f"‚ùå Error generating text: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def generate_text_with_image(self, prompt: str, pil_image: Image.Image = None, image_path: str = None) -> Optional[str]:
        """Generate text with image analysis using Gemini API."""
        try:
            if not GENAI_AVAILABLE:
                print("‚ùå Google GenAI library not available. Please install with: pip install google-genai")
                return None
            
            print(f"üìù Generating text with image analysis using gemini-2.5-pro...")
            print(f"üìù Prompt: {prompt[:100]}...")
            
            # Initialize client with API key
            client = genai.Client(api_key=self.api_key)
            
            # Prepare image data
            if pil_image is not None:
                # Convert PIL image to bytes
                img_byte_arr = io.BytesIO()
                
                # Convert RGBA to RGB if necessary (JPEG doesn't support transparency)
                if pil_image.mode == 'RGBA':
                    # Create white background
                    background = Image.new('RGB', pil_image.size, (255, 255, 255))
                    background.paste(pil_image, mask=pil_image.split()[-1])  # Use alpha channel as mask
                    pil_image = background
                elif pil_image.mode not in ('RGB', 'L'):
                    # Convert other modes to RGB
                    pil_image = pil_image.convert('RGB')
                
                pil_image.save(img_byte_arr, format='JPEG', quality=95)
                image_data = img_byte_arr.getvalue()
            elif image_path is not None:
                # Read image from file
                with open(image_path, 'rb') as f:
                    image_data = f.read()
            else:
                print("‚ùå No image provided")
                return None
            
            print("üì∏ Processing image with Gemini...")
            
            # Use the simplest approach - PIL Image directly
            if pil_image is not None:
                print("üì∏ Using PIL Image directly...")
                contents = [prompt, pil_image]
            else:
                print("üì∏ Loading image from path...")
                # Load image from path and use directly
                pil_image_from_path = Image.open(image_path)
                
                # Apply same RGBA conversion if needed
                if pil_image_from_path.mode == 'RGBA':
                    background = Image.new('RGB', pil_image_from_path.size, (255, 255, 255))
                    background.paste(pil_image_from_path, mask=pil_image_from_path.split()[-1])
                    pil_image_from_path = background
                elif pil_image_from_path.mode not in ('RGB', 'L'):
                    pil_image_from_path = pil_image_from_path.convert('RGB')
                
                contents = [prompt, pil_image_from_path]
            
            # Generate text with image using gemini-2.5-pro
            response = client.models.generate_content(
                model="gemini-2.5-pro",
                contents=contents
            )
            
            if response and response.text:
                print("‚úÖ Text with image analysis generated successfully!")
                return response.text
            else:
                print("‚ùå No text generated from image analysis")
                return None
                
        except Exception as e:
            print(f"‚ùå Error generating text with image: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def _merge_videos(self, video1_path: str, video2_path: str) -> Optional[str]:
        """
        Merge two 8s videos into one 16s video using ffmpeg
        
        Args:
            video1_path: Path to first video
            video2_path: Path to second video
            
        Returns:
            Path to merged video or None if failed
        """
        try:
            import subprocess
            import os
            
            print("üîÑ Merging videos with ffmpeg...")
            
            # Setup merged video path
            video_cache_dir = self.cache_dir.parent / "video_cache"
            video_cache_dir.mkdir(parents=True, exist_ok=True)
            
            merged_filename = f"merged_video_{int(time.time())}.mp4"
            merged_path = video_cache_dir / merged_filename
            
            # Create a temporary file list for ffmpeg concat
            filelist_path = video_cache_dir / f"filelist_{int(time.time())}.txt"
            
            with open(filelist_path, 'w') as f:
                f.write(f"file '{video1_path}'\n")
                f.write(f"file '{video2_path}'\n")
            
            # Use ffmpeg to concatenate videos
            ffmpeg_cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', str(filelist_path),
                '-c', 'copy',
                '-y',  # Overwrite output file
                str(merged_path)
            ]
            
            print(f"üîß Running ffmpeg command: {' '.join(ffmpeg_cmd)}")
            
            # Run ffmpeg
            result = subprocess.run(ffmpeg_cmd, 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=120)
            
            # Clean up temporary file list
            try:
                os.remove(filelist_path)
            except:
                pass
            
            if result.returncode == 0:
                print(f"‚úÖ Videos merged successfully: {merged_path}")
                return str(merged_path)
            else:
                print(f"‚ùå ffmpeg error (return code: {result.returncode})")
                print(f"‚ùå stderr: {result.stderr}")
                print(f"‚ùå stdout: {result.stdout}")
                return None
                
        except subprocess.TimeoutExpired:
            print("‚ùå ffmpeg timeout - merging took too long")
            return None
        except FileNotFoundError:
            print("‚ùå ffmpeg not found. Please install ffmpeg to merge videos")
            return None
        except Exception as e:
            print(f"‚ùå Error merging videos: {str(e)}")
            return None

